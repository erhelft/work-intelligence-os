# Strategic Narrowing Workflow

## Purpose
Systematic process to go from broad vision → validated market entry wedge. Ensures rigorous narrowing through connected analysis phases, avoiding premature optimization or unfounded assumptions.

**Use this when**: Starting a new product idea, exploring market opportunities, or validating strategic direction.

**End result**: Clear go/no-go decision on specific entry wedge with evidence-based rationale.

---

## Process Overview

The workflow narrows through 10 connected phases:

```
Vision → Opportunity → Landscape → Problems → Competition → Framework → Analysis → Validity → Synthesis → Mapping → Decision
```

**Key principle**: Each phase builds on previous outputs. Don't skip steps—narrowing without foundation creates false confidence.

**Timeline**: 3-6 weeks for complete strategic analysis (can compress if time-constrained).

---

## Phase 0: Vision

### Goal
Define the transformative long-term outcome and strategic horizons (short-term entry vs. long-term transformation).

### High-Level Structure
- **Two-horizon strategy**: Short-term (solve immediate pain) vs. Long-term (transformative vision)
- **Transformative thesis**: What becomes possible that wasn't before? Why does it matter?
- **Strategic examples**: Concrete illustrations of transformation at scale
- **Not included**: Specific market segments, competitive positioning, or entry tactics

### Connection to Process
- **Feeds into**: Opportunity (validates why this domain), Problems (what transformation solves)
- **Grounds later work**: Prevents getting lost in tactics; maintains North Star
- **Tension with entry**: Vision is expansive; entry is narrow—this is healthy tension

### Guidelines to Verify/Follow
- ✅ Can articulate transformation in one sentence to non-technical person
- ✅ Two horizons are distinct: entry solves pain today, vision transforms workflow tomorrow
- ✅ Concrete examples show "what's impossible today becomes possible"
- ✅ Vision is ambitious but not science fiction—grounded in emerging capability

### Common Pitfalls
- ❌ **Vision = feature list**: "We'll have AI and analytics" (not transformative)
- ❌ **No horizon distinction**: Conflating short-term entry with long-term vision
- ❌ **Too abstract**: "Revolutionize industry" without concrete mechanisms
- ❌ **Starting with entry wedge**: Picking tactic before understanding strategy

### Output
**Artifact**: Vision document (1-2 pages)

**Serves**: Grounds all subsequent analysis; prevents premature narrowing; maintains ambition while enabling focused entry.

---

## Phase 1: Opportunity

### Goal
Validate why THIS domain/primitive is the right opportunity space (not yet which segment or use case).

### High-Level Structure
- **Market fundamentals**: Why this primitive/space matters (universal reach, business criticality, distribution)
- **Opportunity advantages**: 3-5 structural reasons this space is attractive (not specific to entry wedge)
- **Strategic leverage**: How entry in this space creates platform/expansion opportunities
- **Scope definition**: What's IN scope (domain boundaries) and OUT of scope

### Connection to Process
- **Based on**: Vision (why transformation matters)
- **Feeds into**: Landscape (what types exist in this domain), Problems (what's broken universally)
- **Decision point**: Is this domain worth pursuing? (If no, pivot to different domain)

### Guidelines to Verify/Follow
- ✅ Can explain why THIS domain vs. alternatives (forms vs. surveys vs. workflows)
- ✅ Advantages are structural, not dependent on specific entry point
- ✅ Scope is clear: what counts as in-domain vs. adjacent
- ✅ Platform potential visible: how wedge → expansion works

### Common Pitfalls
- ❌ **Too narrow too fast**: "Shopify returns" when you mean "e-commerce operations"
- ❌ **Unfounded assumptions**: "This is a $X billion market" without evidence
- ❌ **Skipping domain validation**: Jumping to specific use case before validating domain
- ❌ **No expansion logic**: Entry wedge with no clear path to platform

### Output
**Artifact**: Opportunity document (1-2 pages)

**Serves**: Validates domain choice; prevents wasting effort in wrong space; sets scope for landscape mapping.

---

## Phase 2: Landscape

### Goal
Map the domain comprehensively through systematic discovery—find natural categories based on meaningful dimensions, then characterize each category to understand uniqueness and opportunities.

### High-Level Structure

**Step 2A: Define Primitive & Hypothesize Dimensions**
- Identify the atomic unit (forms, calendar events, emails, notifications)
- Hypothesize 5-8 dimensions that might drive meaningful differences
  - Examples: incentive alignment, control dynamics, value exchange, motivation, relationship context
- Dimensions should reveal structural differences, not surface attributes

**Step 2B: Explore & Discover Categories (Inductive)**
- Collect 20-30 diverse examples of the primitive across domain
- Apply hypothesized dimensions to each example (quick assessment)
- Watch for natural clustering patterns across dimensions
- Iterate dimensions: drop unhelpful ones, add new ones as patterns emerge
- Let categories emerge from the data, don't force them

**Step 2C: Define & Name Categories**
- Based on exploration, identify 4-6 natural groupings
- Name categories based on defining characteristics (not generic labels)
- Ensure MECE (mutually exclusive, collectively exhaustive)
- Test: Can you quickly categorize any new example into exactly one category?

**Step 2D: Characterize Each Category Systematically**
- Create consistent characterization template for all categories
- Per category, document:
  - Purpose & definition (boundaries, 3-5 examples)
  - Dimension analysis (apply same dimensions to each for comparison)
  - Current state (how solved today, what's broken, what trade-offs)
  - Success definition (what good looks like)
- Use same structure for each category to enable pattern identification

### Connection to Process
- **Based on**: Opportunity (domain boundaries, primitive definition)
- **Feeds into**: Problems (which categories have which problems), Competition (where competitors focus)
- **Maintains breadth**: Resist narrowing—comprehensively map before evaluating
- **Enables comparison**: Systematic characterization reveals patterns across categories

### Guidelines to Verify/Follow
- ✅ Primitive is clearly defined (atomic unit, scope boundaries)
- ✅ Dimensions reveal structural differences (not surface attributes like "size" or "B2B vs B2C")
- ✅ Categories emerged from exploration (not predetermined before looking at examples)
- ✅ Each category characterized on same dimensions (enables comparison)
- ✅ Categories are MECE with 3-5 clear examples each
- ✅ Framework reveals patterns (e.g., "misaligned incentives behave differently")
- ✅ No premature evaluation: describing and characterizing, not judging yet

### Common Pitfalls
- ❌ **Skipping exploration**: Defining categories before looking at examples (deductive not inductive)
- ❌ **Surface dimensions**: "B2B vs B2C" or "large vs small" instead of structural characteristics
- ❌ **Evaluating while mapping**: "This category is better" (too early—just characterize)
- ❌ **Incomplete coverage**: Missing category because it seems less interesting
- ❌ **Overcomplicating**: 15 micro-categories instead of 4-6 meaningful ones
- ❌ **Inconsistent characterization**: Different dimensions per category (breaks comparison)
- ❌ **Forcing predetermined categories**: Making examples fit preconceived buckets

### Output
**Artifact**: Landscape document (4-6 pages)
- **Section 1**: Primitive definition & dimension framework (1 page)
- **Section 2**: Category taxonomy overview (0.5 page)
- **Section 3**: Per-category characterization (0.5-1 page each × 4-6 categories)
- **Section 4**: Cross-category patterns observed (0.5 page)

**Serves**: 
- Comprehensive view prevents blind spots
- Systematic characterization reveals category-specific problems
- Pattern recognition across categories surfaces opportunities
- Feeds into Problems phase (which categories have which issues)
- Enables later scoring (categories become units of analysis)
---

## Phase 3: Problems & Solutions

### Goal
Identify universal problems in domain and map solutions (defines what you're building against—the "how").

### High-Level Structure
- **Problem A**: Immediate pain users/builders feel today (tactical)
- **Problem B**: Systemic limitation preventing improvement (strategic)
- **Opportunity C**: Transformative potential (long-term vision)
- **Per problem**: Current state, why it exists, who it affects, how is it solved as of today, solution approach
- **Include dissenting views**: Why this might NOT be problem, assumptions required

### Connection to Process
- **Based on**: Landscape (which categories have which problems), Vision (transformation = solving B+C)
- **Feeds into**: Framework (how to score forms on these problems), Competition (who solves what)
- **Critical for**: Defining your value proposition (you solve A+B+C together)

### Guidelines to Verify/Follow
- ✅ Problems are outcome-focused ("teams waste $X") not feature-focused ("no AI")
- ✅ Each problem validated across multiple categories from landscape
- ✅ Solution approaches are distinct (different mechanisms, not same thing 3 ways)
- ✅ Dissenting views force you to confront assumptions early

### Common Pitfalls
- ❌ **Feature problems**: "Forms don't have AI" (describes solution, not problem)
- ❌ **Single problem thinking**: Only identifying one dimension of pain
- ❌ **Solution-first**: Defining problems around your technology vs. real pain
- ❌ **No validation**: Assuming problems exist without evidence from landscape

### Output
**Artifact**: Problems & Solutions document (3-5 pages)

**Serves**: Defines what you're building (solution approach); enables scoring forms against problems; grounds value proposition in real pain.

---

## Phase 4: Competition

### Goal
Map competitive landscape to identify white space, saturation, and strategic positioning opportunities.

### High-Level Structure
- **Competitor segmentation**: 3-4 categories (surveys, forms, AI research, etc.)
- **Per segment**: Player count, positioning, saturation signals, gaps
- **Pattern analysis**: Where competitors cluster vs. avoid
- **White space identification**: What's NOT being solved and why
- **Strategic recommendations**: Categories to avoid, pursue, or test

### Connection to Process
- **Based on**: Landscape (what categories exist), Problems (what competitors solve)
- **Feeds into**: Framework (competition as scoring dimension), Positioning (how to differentiate)
- **Reality check**: Validates or invalidates opportunity assumptions

### Guidelines to Verify/Follow
- ✅ 30+ competitors mapped across segments (comprehensiveness matters)
- ✅ Clear saturation vs. white space identification with evidence
- ✅ Understand WHY white space exists (opportunity or graveyard?)
- ✅ Competitive positioning emerges from gaps, not from features

### Common Pitfalls
- ❌ **Ignoring "boring" competitors**: Only mapping sexy AI startups, missing incumbents
- ❌ **Feature comparison trap**: "We have X, they don't" without strategic insight
- ❌ **Assuming white space = opportunity**: Could be graveyard, validate why empty
- ❌ **Confirmation bias**: Only finding competitors that validate your approach

### Output
**Artifact**: Competition document (5-10 pages)

**Serves**: Identifies white space opportunities; prevents entering saturated markets; informs positioning strategy; validates opportunity or triggers pivot.

---

## Phase 5: Market Entry Framework

### Goal
Create systematic scoring framework to evaluate each form type against Problems A/B/C—makes evaluation rigorous and comparable.

### High-Level Structure
- **Problem A parameters** (5): Scoring dimensions for immediate pain
- **Problem B parameters** (5): Scoring dimensions for systemic limitations  
- **Opportunity C parameters** (4): Scoring dimensions for transformation potential
- **Rating guidelines**: 1-10 scales with clear definitions per parameter
- **Weighting rationale**: Why weight differently (e.g., 50% A, 30% B, 20% C)
- **Not included yet**: Actual scoring of forms (that's next phase)

### Connection to Process
- **Based on**: Problems (what to score against), Landscape (what form types to score)
- **Feeds into**: Analysis (apply framework to each form), Validity (add business lens)
- **Critical for**: Converting qualitative assessment to comparable quantitative scores

### Guidelines to Verify/Follow
- ✅ Parameters are mutually exclusive (not scoring same thing twice)
- ✅ 1-10 scales have clear definitions (6 vs. 7 is meaningful, not arbitrary)
- ✅ Weighting reflects strategic priorities (entry pain vs. long-term value)
- ✅ Framework is domain-agnostic enough to apply consistently

### Common Pitfalls
- ❌ **Overlapping parameters**: Scoring same concept multiple times inflates scores
- ❌ **Vague scales**: "7/10 means moderate" (not specific enough)
- ❌ **Equal weighting**: Not reflecting that entry pain matters more than future vision
- ❌ **Overcomplicating**: 20 parameters instead of 14—diminishing returns

### Output
**Artifact**: Framework document (2-4 pages)

**Serves**: Enables systematic, comparable scoring of all form types; makes analysis rigorous not arbitrary; allows pattern identification across scores.

---

## Phase 6: Wedge Analysis

### Goal
Apply framework to score each form type, identify patterns, and surface top entry wedge candidates based on product/problem fit.

### High-Level Structure
- **Per form type**: Score all 14 parameters with justification
- **Master scores**: Calculate Problem A, B, C averages
- **Weighted scores**: Apply weighting (50/30/20) for overall wedge score
- **Rankings**: Top 10 by overall score, by each problem dimension
- **Pattern analysis**: What characteristics drive high scores? Category patterns?
- **Insights**: Emergent findings about form types, problems, opportunities

### Connection to Process
- **Based on**: Framework (scoring method), Landscape (form types), Problems (what to score)
- **Feeds into**: Validity (add business lens to top scorers), Synthesis (combine both lenses)
- **First major filter**: Eliminates low-scoring options, surfaces top 10-15 candidates

### Guidelines to Verify/Follow
- ✅ Every score has brief justification (not arbitrary numbers)
- ✅ Patterns emerge organically from scores (adversarial forms cluster, etc.)
- ✅ Top scorers make intuitive sense (if surprising, validate assumptions)
- ✅ Consistent rating approach (not easier on forms you like)

### Common Pitfalls
- ❌ **Scoring to outcome**: Rating forms higher because you want them to win
- ❌ **Inconsistent standards**: Harsh on some, lenient on others
- ❌ **Ignoring patterns**: Missing that adversarial forms all score high (insight!)
- ❌ **No justification**: Just numbers without reasoning (can't validate later)

### Output
**Artifact**: Wedge Analysis document (15-30 pages)

**Serves**: Narrows from all form types to top 10-15 candidates; surfaces patterns for synthesis; provides product-fit lens for decision.

---

## Phase 7: Business Validity

### Goal
Evaluate top candidates through business lens (market size, GTM friction)—ensures product-fit doesn't blind you to business reality.

### High-Level Structure
- **Opportunity Size** (4 parameters): Business impact, attribution clarity, transaction volume, market breadth
- **GTM Friction** (4 parameters): Integration ease, time to value, budget ownership, competition
- **Per top candidate**: Score 8 parameters with justification
- **Rankings**: Top 10 by business validity, identify high opportunity + low friction
- **Reality checks**: What looked good on product-fit but fails business test?

### Connection to Process
- **Based on**: Wedge Analysis (top scorers to evaluate), Competition (competition parameter)
- **Feeds into**: Synthesis (combine product + business lens), Final Mapping (overall scores)
- **Critical filter**: High product-fit + bad business = science project, not startup

### Guidelines to Verify/Follow
- ✅ Brutal honesty on friction (can you really prove value in 8 weeks?)
- ✅ Market size is breadth (# companies) not depth (importance of companies)
- ✅ Business impact = direct P&L this quarter, not eventual strategic value
- ✅ Some high wedge scorers will fail business test—this is good, not bad

### Common Pitfalls
- ❌ **Confusing importance with impact**: "Hiring is critical → job apps = 9/10" (wrong—form improvement is indirect)
- ❌ **Optimistic friction**: "We can integrate easily" (really? have you tried?)
- ❌ **Market size confusion**: "Big companies use this → 9/10" (breadth, not company size)
- ❌ **Ignoring competition**: "We're better" (doesn't matter if crowded)

### Output
**Artifact**: Business Validity document (15-25 pages)

**Serves**: Filters product-fit candidates through business reality; surfaces clear winners; prevents pursuing viable product but unviable business.

---

## Phase 8: Synthesis

### Goal
Combine product-fit + business validity lenses to derive decision patterns and strategic principles—distill learnings into actionable framework.

### High-Level Structure
- **5 strategic gates**: Decision criteria distilled from analysis patterns
- **Key patterns**: What makes opportunities viable vs. risky (adversarial forms, etc.)
- **Anti-patterns**: What to avoid (general forms, surveys, saturated markets)
- **Quick filters**: Speed-to-value, scale, buyer, pattern match, competition
- **Decision rules**: When to pursue, pivot, or abort

### Connection to Process
- **Based on**: Wedge Analysis + Business Validity (combined insights)
- **Feeds into**: Final Mapping (apply gates to rank candidates)
- **Purpose**: Convert 50+ pages of analysis into 5-page decision framework

### Guidelines to Verify/Follow
- ✅ Gates are independent (passing one doesn't guarantee passing another)
- ✅ Patterns are evidence-based (from your analysis, not generic wisdom)
- ✅ Abort criteria as clear as proceed criteria (knowing when to stop matters)
- ✅ Framework is memorable (can explain 5 gates without looking at doc)

### Common Pitfalls
- ❌ **Generic platitudes**: "Pick big markets" (not specific to your analysis)
- ❌ **Too complex**: 15 criteria no one can remember vs. 5 clear gates
- ❌ **Ignoring failures**: Only codifying successes, not what to avoid
- ❌ **Analysis paralysis**: Synthesis should simplify, not add complexity

### Output
**Artifact**: Synthesis document (3-5 pages)

**Serves**: Actionable decision framework; enables quick evaluation of new candidates; grounds final mapping decisions; reusable for future opportunities.

---

## Phase 9: Final Mapping

### Goal
Combine all lenses (wedge score + business validity) and apply gates to make final go/no-go decision on top 3-5 candidates.

### High-Level Structure
- **Overall scores**: (Wedge Score + Business Validity) / 2
- **Top 10 ranking**: By overall score with both components visible
- **Gate evaluation**: Apply 5 gates to each top candidate (pass/fail per gate)
- **Tier 1 (5/5 gates)**: Primary entry candidates
- **Tier 2 (4/5 gates)**: Conditional opportunities (need clear advantage)
- **Tier 3 (<4 gates)**: Abort (insufficient evidence)
- **Final recommendation**: Ranked 1-2-3 with expansion path

### Connection to Process
- **Based on**: All previous phases (comprehensive synthesis)
- **Feeds into**: Market entry decision, customer discovery priorities
- **Final output**: Clear recommendation with evidence trail

### Guidelines to Verify/Follow
- ✅ Top scorers pass sanity check (do these actually make sense?)
- ✅ Gate failures are explicit (understand why 4/5 not 5/5)
- ✅ Tier distinctions are meaningful (pursue vs. conditional vs. abort)
- ✅ Can trace any recommendation back to evidence in earlier docs

### Common Pitfalls
- ❌ **Ignoring gate failures**: "4/5 is close enough" (gates exist for reason)
- ❌ **Overriding analysis**: Picking favorite despite scores (invalidates process)
- ❌ **Analysis paralysis**: "Need more data" when decision is clear
- ❌ **No expansion logic**: Picking entry without clear path forward

### Output
**Artifact**: Final Mapping document (10-15 pages)

**Serves**: Clear go/no-go decision; prioritized entry wedges; evidence-based rationale; expansion roadmap.

---

## Phase 10: Entry Validation

### Goal
Create focused one-pager for chosen entry wedge to guide customer discovery and validation work.

### High-Level Structure
- **Problem**: Multi-dimensional pain (not single metric)
- **Opportunity**: Category creation positioning
- **Target audience**: Platform-agnostic until validated
- **Hypothesis**: What you believe, how to test
- **Success metrics**: Multi-dimensional proof points
- **Go/no-go criteria**: When to proceed, pivot, or abort

### Connection to Process
- **Based on**: Final Mapping (chosen entry), all previous analysis (evidence)
- **Shifts focus**: From strategic analysis → tactical validation
- **Purpose**: Actionable guide for next 4-6 weeks of customer discovery

### Guidelines to Verify/Follow
- ✅ Problems framed as business outcomes (not feature gaps)
- ✅ Multi-stakeholder value (not single buyer/metric)
- ✅ Platform/segment marked "TO BE VALIDATED" (not premature assumption)
- ✅ Clear abort criteria (know when to pivot)

### Common Pitfalls
- ❌ **Premature platform lock**: "Shopify only" before validating pain across platforms
- ❌ **Feature framing**: "System doesn't learn" vs. "Blind shipping costs $X"
- ❌ **Single metric**: "Reduce fraud 30%" (invites commodity comparison)
- ❌ **No abort criteria**: Only success cases, not failure triggers

### Output
**Artifact**: Entry one-pager (3-5 pages)

**Serves**: Guides customer discovery; focuses validation work; maintains category positioning; enables fast pivot decisions.

---

## Meta-Guidelines: Using This Workflow

### When to Use Full Process
- **New product idea**: Starting from scratch, need comprehensive analysis
- **Strategic pivot**: Reconsidering market position, need evidence-based decision
- **Investor-grade diligence**: Building case for funding, need rigorous framework

### When to Compress/Skip
- **Time-constrained**: Can combine phases (Landscape + Problems, Analysis + Validity)
- **Narrow domain**: If domain clearly defined, can skip Opportunity phase
- **Strong hypothesis**: If clear entry wedge, start at Validity to stress-test

### Quality Checks at Each Phase
1. **Can you explain it simply?** If not, you don't understand it yet
2. **Is it evidence-based?** No unfounded assumptions or "we believe" without data
3. **Does it connect?** Each phase should reference and build on previous
4. **Would it change your mind?** If analysis confirms only what you wanted, redo it

### Red Flags to Abort Process
- **Can't quantify pain**: No one can estimate dollar losses → not urgent enough
- **Saturated competition**: 10+ well-funded players → need unfair advantage
- **No white space**: Every angle covered → wrong timing or wrong market
- **Category rejection**: Customers force commodity comparison → can't create category

### Success Signals
- **Convergence**: Multiple lenses (product, business, competition) point to same entry
- **Surprises**: Analysis reveals non-obvious opportunities (adversarial forms pattern)
- **Clear abort criteria**: Know when to stop, not just when to go
- **Expansion logic**: Entry wedge has clear path to platform/scale

---

## Workflow Outputs Summary

| Phase | Document | Size | Key Insight |
|-------|----------|------|-------------|
| 0. Vision | Vision doc | 1-2 pg | What transforms long-term |
| 1. Opportunity | Opportunity doc | 1-2 pg | Why this domain |
| 2. Landscape | Landscape doc | 3-5 pg | Comprehensive taxonomy |
| 3. Problems | Problems doc | 3-5 pg | What you're solving |
| 4. Competition | Competition doc | 5-10 pg | White space identification |
| 5. Framework | Framework doc | 2-4 pg | Scoring methodology |
| 6. Wedge Analysis | Analysis doc | 15-30 pg | Product-fit ranking |
| 7. Business Validity | Validity doc | 15-25 pg | Business-fit ranking |
| 8. Synthesis | Synthesis doc | 3-5 pg | Decision framework |
| 9. Final Mapping | Mapping doc | 10-15 pg | Final recommendation |
| 10. Entry Validation | One-pager | 3-5 pg | Validation guide |

**Total**: 60-110 pages of analysis → Clear go/no-go decision with evidence trail

**Timeline**: 3-6 weeks (can compress to 2-3 weeks if time-constrained)

---

## Adapting This Workflow

### For Different Domains
- **SaaS tools**: Focus on workflow replacement vs. feature improvement
- **Marketplaces**: Add supply/demand dynamics to landscape
- **Infrastructure**: Emphasize technical unlock and compounding value
- **Consumer apps**: Add behavioral psychology and viral mechanics

### For Different Stages
- **Pre-idea**: Start at Phase 0-1 (broad exploration)
- **Idea validation**: Start at Phase 2-3 (assume domain, validate opportunity)
- **Product-market fit search**: Start at Phase 6-7 (assume problems, find best entry)
- **Expansion planning**: Use Phases 8-10 (leverage existing analysis, find adjacency)

### Maintaining Quality Through Compression
If you must compress, combine phases but don't skip:
- **Problem identification** (Phase 3): Everything depends on this
- **Competition validation** (Phase 4): Prevents entering graveyards
- **Business reality check** (Phase 7): Prevents science projects
- **Synthesis** (Phase 8): Makes analysis actionable

**Never skip**: Competition and Business Validity—most common failure points.

---

## Example: This Workflow in Action

**Starting point**: "AI-native forms" (broad vision)

**After Phase 2** (Landscape): Identified 5 form categories, adversarial forms pattern emerged

**After Phase 4** (Competition): Found white space in adversarial forms, saturation in general forms/surveys

**After Phase 6** (Wedge Analysis): Top scorers were Abuse Report, Vendor Risk, Returns, Job Apps

**After Phase 7** (Business Validity): Returns dominated (9.13), Abuse Report dropped to #14 (market size overestimated)

**After Phase 9** (Final Mapping): Returns (5/5 gates), Warranty (5/5 gates), others conditional/abort

**Result**: "Intelligent Returns for E-commerce" - clear entry with expansion path (Warranty → Churn → Claims)

**Evidence**: 60+ pages of analysis, multiple lenses converged on same answer, clear abort criteria defined

**Time**: 4 weeks of rigorous analysis prevented months of building wrong thing

---

## Final Checklist: Ready for Customer Discovery?

Before moving to validation, ensure:

- [ ] **Multi-dimensional value**: 3+ value streams targeting different stakeholders (not single metric)
- [ ] **Category positioning**: New category defined, not feature comparison to existing
- [ ] **Platform-agnostic**: Segment/platform marked "TO BE VALIDATED" (not premature lock)
- [ ] **Outcome-framed problems**: Business impacts quantifiable (not feature gaps)
- [ ] **White space validated**: Competition mapped, clear gap with explanation why it exists
- [ ] **Evidence trail**: Can trace every recommendation back to analysis in earlier phases
- [ ] **Abort criteria**: Clear triggers for pivot or kill (not just proceed criteria)
- [ ] **Expansion logic**: Entry wedge → Year 2 → Year 3 → Platform vision clear

If all checked, proceed to customer discovery with confidence. If gaps exist, iterate relevant phases before investing in validation.

